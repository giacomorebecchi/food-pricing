{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.xgb import XGBBERTResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = XGBBERTResNet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "# Suppressing warnings because of skopt verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifier/Regressor\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_perf(optimizer, X, y, title=\"Model\", callbacks=None):\n",
    "    start = time()\n",
    "    \n",
    "    if callbacks is not None:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "        \n",
    "    d=pd.DataFrame(optimizer.cv_results_)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "    best_params = optimizer.best_params_\n",
    "    \n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "           + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "                                   len(optimizer.cv_results_['params']),\n",
    "                                   best_score,\n",
    "                                   best_score_std))    \n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    print()\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.parsing import AttributeDict\n",
    "\n",
    "hparams = AttributeDict(\n",
    "    {\n",
    "        \"random_state\": 42,\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_splits\": 5,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = XGBRegressor(\n",
    "    random_state=hparams.random_state,\n",
    "    booster=hparams.booster,\n",
    "    objective=hparams.objective,\n",
    "    # eval_metric=mean_squared_error,\n",
    "    tree_method=hparams.tree_method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = make_scorer(partial(mean_squared_error, squared=False), greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([model.X_train, model.X_dev])\n",
    "y = np.hstack([model.y_train, model.y_dev])\n",
    "\n",
    "y_stratified = pd.cut(pd.Series(y).rank(method='first'), bins=10, labels=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=7,\n",
    "                      shuffle=True, \n",
    "                      random_state=0)\n",
    "\n",
    "cv_strategy = list(skf.split(X, y_stratified))\n",
    "\n",
    "# cv_strategy = [(np.arange(len(model.y_train)), np.arange(len(model.y_train), len(y)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {'learning_rate': Real(0.01, 1.0, 'uniform'),\n",
    "                 'max_depth': Integer(2, 12),\n",
    "                 'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "                 'colsample_bytree': Real(0.1, 1.0, 'uniform'), # subsample ratio of columns by tree\n",
    "                 'reg_lambda': Real(1e-9, 100., 'uniform'), # L2 regularization\n",
    "                 'reg_alpha': Real(1e-9, 100., 'uniform'), # L1 regularization\n",
    "                 'n_estimators': Integer(50, 5000)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping everything up into the Bayesian optimizer\n",
    "opt = BayesSearchCV(estimator=reg,\n",
    "                    search_spaces=search_spaces,                                                       \n",
    "                    scoring=scoring,                                   \n",
    "                    cv=cv_strategy,                                          \n",
    "                    n_iter=120,                                       # max number of trials\n",
    "                    n_points=1,                                       # number of hyperparameter sets evaluated at the same time\n",
    "                    n_jobs=1,                                         # number of jobs\n",
    "                    iid=False,                                        # if not iid it optimizes on the cv score\n",
    "                    return_train_score=False,\n",
    "                    verbose=2,                         \n",
    "                    refit=False,                                      \n",
    "                    optimizer_kwargs={\"base_estimator\": \"GP\"},        # optmizer parameters: we use Gaussian Process (GP)\n",
    "                    random_state=hparams.random_state)                # random state for replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time=12.2min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time= 8.6min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time= 8.5min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time= 8.7min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time=16.0min\n",
      "[CV] END colsample_bytree=0.46909356296798244, learning_rate=0.7304484857455519, max_depth=11, n_estimators=1613, reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, subsample=0.41583820140922967; total time= 8.1min\n",
      "XGBoost Regression took 4254.26 seconds,  candidates checked: 1, best CV score: -591.632 ± 30.597\n",
      "Best parameters:\n",
      "OrderedDict([('colsample_bytree', 0.46909356296798244),\n",
      "             ('learning_rate', 0.7304484857455519),\n",
      "             ('max_depth', 11),\n",
      "             ('n_estimators', 1613),\n",
      "             ('reg_alpha', 67.01479482722331),\n",
      "             ('reg_lambda', 41.41186324913973),\n",
      "             ('subsample', 0.41583820140922967)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running the optimizer\n",
    "overdone_control = DeltaYStopper(delta=1)                    # We stop if the gain of the optimization becomes too small\n",
    "time_limit_control = DeadlineStopper(total_time=60*20)\n",
    "\n",
    "optimizer = report_perf(opt, X, y,\"XGBoost Regression\", \n",
    "                          callbacks=[overdone_control, time_limit_control])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg = XGBRegressor(\n",
    "    random_state=hparams.random_state,\n",
    "    booster=hparams.booster,\n",
    "    objective=hparams.objective,\n",
    "    eval_metric=mean_squared_error,\n",
    "    tree_method=hparams.tree_method,\n",
    "    **optimizer.best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.46909356296798244, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=&lt;function mean_squared_error at 0x7f407f52eaf0&gt;,\n",
       "             gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.7304484857455519,\n",
       "             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=11,\n",
       "             max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=1613, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "             reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.46909356296798244, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=&lt;function mean_squared_error at 0x7f407f52eaf0&gt;,\n",
       "             gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.7304484857455519,\n",
       "             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=11,\n",
       "             max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=1613, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "             reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.46909356296798244, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=<function mean_squared_error at 0x7f407f52eaf0>,\n",
       "             gamma=0, gpu_id=-1, grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.7304484857455519,\n",
       "             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=11,\n",
       "             max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1613, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=67.01479482722331, reg_lambda=41.41186324913973, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_reg.fit(model.X_train, model.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378001.03"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_reg.predict(model.X_test)\n",
    "mean_squared_error(pred, model.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7baf0a9355b2187f13b56e3fae033a6ce164fc9add6d7138e9a4da0d4f49a6ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
