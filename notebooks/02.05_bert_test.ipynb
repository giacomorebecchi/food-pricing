{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.models.utils.data import FoodPricingDataset\n",
    "from src.models.nlp.pretrained_bert import PreTrainedBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PreTrainedBERT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"dbmdz/bert-base-italian-xxl-uncased\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:root:Loading the tokenizer with the same name of the model for the PretrainedBERT.\n"
     ]
    }
   ],
   "source": [
    "feature_dim = None\n",
    "model = PreTrainedBERT(model_kwargs, feature_dim=feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(\n",
    "        #     mean=[0.485, 0.456, 0.406],\n",
    "        #     std=[0.229, 0.224, 0.225],\n",
    "        # )\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_data = FoodPricingDataset(\n",
    "    img_transform=img_transform, txt_transform=lambda x: x, split=\"train\"\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    training_data,\n",
    "    shuffle=True,\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    ")\n",
    "sample = next(iter(dataloader))[\"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb.shape[0] == len(sample)\n",
    "assert sent_emb.shape[1] == feature_dim or model.bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(pretrained_model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "model = AutoModel.from_pretrained(pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_batch = tokenizer(sample, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che\n",
      "##ese\n",
      "##burg\n",
      "##er\n",
      "emp\n",
      "##ty\n",
      "_\n",
      "descri\n",
      "##ption\n",
      "[SEP]\n",
      "carre\n",
      "##fo\n",
      "##ur\n",
      "caffe\n",
      "'\n",
      "espresso\n",
      "cre\n",
      "##mos\n",
      "##o\n",
      "250\n",
      "g\n",
      "-\n",
      "89\n",
      "##93\n",
      "caffe\n",
      "'\n",
      "macina\n",
      "##to\n",
      "espresso\n",
      "cr\n",
      "##f\n",
      "[SEP]\n",
      "val\n",
      "##cale\n",
      "##pio\n",
      "rosso\n",
      "magri\n",
      "sereno\n",
      "doc\n",
      "75\n",
      "##cl\n",
      "emp\n",
      "##ty\n",
      "_\n",
      "descri\n",
      "##ption\n",
      "[SEP]\n",
      "pane\n",
      "##angeli\n",
      "lievito\n",
      "vani\n",
      "##gli\n",
      "##nato\n",
      "x\n",
      "##3\n",
      "48\n",
      "g\n",
      "-\n",
      "00\n",
      "##97\n",
      "136\n",
      "##10\n",
      "lievito\n",
      "x\n",
      "3\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "t: torch.Tensor = encoded_batch[\"input_ids\"]\n",
    "flat_t = t.reshape(t.numel()).tolist()\n",
    "for el in flat_t:\n",
    "    if (s := tokenizer.convert_ids_to_tokens(el)) not in (\"[CLS]\", \"[PAD]\"):\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = model(encoded_batch[\"input_ids\"], encoded_batch[\"attention_mask\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = word_embeddings[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.4502798318862915 between sentences: \n",
      "Carrefour Caffe' Espresso Cremoso 250 g - 8993 CAFFE' MACINATO ESPRESSO CRF\n",
      "Cheeseburger EMPTY_DESCRIPTION\n",
      "\n",
      "Similarity: 0.2242051661014557 between sentences: \n",
      "Valcalepio Rosso Magri Sereno Doc 75cl EMPTY_DESCRIPTION\n",
      "Cheeseburger EMPTY_DESCRIPTION\n",
      "\n",
      "Similarity: 0.8813031911849976 between sentences: \n",
      "Valcalepio Rosso Magri Sereno Doc 75cl EMPTY_DESCRIPTION\n",
      "Carrefour Caffe' Espresso Cremoso 250 g - 8993 CAFFE' MACINATO ESPRESSO CRF\n",
      "\n",
      "Similarity: 0.3547227084636688 between sentences: \n",
      "Paneangeli Lievito vaniglinato X3 48 g - 0097 13610 LIEVITO X 3\n",
      "Cheeseburger EMPTY_DESCRIPTION\n",
      "\n",
      "Similarity: 0.9442523717880249 between sentences: \n",
      "Paneangeli Lievito vaniglinato X3 48 g - 0097 13610 LIEVITO X 3\n",
      "Carrefour Caffe' Espresso Cremoso 250 g - 8993 CAFFE' MACINATO ESPRESSO CRF\n",
      "\n",
      "Similarity: 0.920947790145874 between sentences: \n",
      "Paneangeli Lievito vaniglinato X3 48 g - 0097 13610 LIEVITO X 3\n",
      "Valcalepio Rosso Magri Sereno Doc 75cl EMPTY_DESCRIPTION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i1, i2 in [(i, j) for i in range(len(sample)) for j in range(i)]:\n",
    "    sim = torch.cosine_similarity(sentence_embeddings[i1,:], sentence_embeddings[i2,:], dim=0).item()\n",
    "    print(f\"Similarity: {sim} between sentences: \\n{sample[i1]}\\n{sample[i2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Panino con bacon e formaggio asiago: offerta speciale!\"\n",
    "encoded_input = tokenizer.encode(s)\n",
    "input_ids = torch.tensor(encoded_input).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('food-pricing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7baf0a9355b2187f13b56e3fae033a6ce164fc9add6d7138e9a4da0d4f49a6ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
